{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfideU0/4+FdV4F7QsLb5I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spicy-shawarma/HDC/blob/main/Capacity_Analysis_of_MAP%2C_HRR%2C_FHRR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import random\n",
        "from multiprocessing import Pool\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "82IQe1FE4GBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAP, copied here just for completeness. For some reason, no normalization works pretty well in preserving similarity\n"
      ],
      "metadata": {
        "id": "WAOXifCcMhOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_MAP_vector(n):\n",
        "  vec = np.array([random.choice(([-1, 1])) for _ in range(n)])\n",
        "  return vec\n",
        "\n",
        "def MAP_bind(vector1, vector2):\n",
        "  return np.multiply(vector1, vector2)\n",
        "\n",
        "def MAP_bundle(*args):\n",
        "\n",
        "  ret = np.zeros(len(args[0][0]))\n",
        "  for v in args[0]:\n",
        "\n",
        "    ret = np.add(ret, v)\n",
        "    ###ret = np.where(ret >= 0, 1, -1)\n",
        "  return ret\n",
        "\n",
        "def MAP_permute(vector1):\n",
        "  return np.roll(vector1, 1, axis=None)\n",
        "\n",
        "def MAP_similarity(vector1, vector2):\n",
        "  return dot(vector1, vector2)/(norm(vector1)*norm(vector2))"
      ],
      "metadata": {
        "id": "7zhUQfI9Mgti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Holographic Reduced Representation:\n"
      ],
      "metadata": {
        "id": "521BlAnTCcSU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu-kt7ZijhIQ"
      },
      "outputs": [],
      "source": [
        "def generate_HRR_vector(n):\n",
        "    variance = 1 / n\n",
        "    std_deviation = np.sqrt(variance)\n",
        "    vector = np.random.normal(0, std_deviation, n)\n",
        "    return vector\n",
        "\n",
        "def bind_HRR(vec1, vec2):\n",
        "  n = len(vec1)\n",
        "  bound_vec = np.zeros(n)\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      bound_vec[i] += (vec1[j%n] * vec2[(j-i)%n])\n",
        "  return bound_vec\n",
        "\n",
        "def bundle_HRR(*args):\n",
        "  ret = np.zeros(len(args[0][0]))\n",
        "  for v in args[0]:\n",
        "    ret = np.add(ret, v)\n",
        "\n",
        "  l2 = norm(ret)\n",
        "  if l2 == 0:\n",
        "     raise ValueError(\"For some reason, bundled vec is the 0 vector\")\n",
        "\n",
        "  return (ret / l2)\n",
        "\n",
        "def similarity_HRR(vector1, vector2):\n",
        "  return dot(vector1, vector2)/(norm(vector1)*norm(vector2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fourier Holographic Reduced Representation:"
      ],
      "metadata": {
        "id": "59Ww-UsvCf2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_FHRR_vector(n):\n",
        "  v = np.zeros(n, dtype=complex)\n",
        "  for i in range(n):\n",
        "    angle = (np.random.uniform((-1 * np.pi), np.pi))\n",
        "    phasor = np.exp(1j * angle)\n",
        "    v[i] = phasor/np.sqrt((np.real(phasor)**2) + (np.imag(phasor)**2))\n",
        "  return v\n",
        "\n",
        "def bind_FHRR(vec1, vec2):\n",
        "  return np.multiply(vec1, vec2)\n",
        "\n",
        "def bundle_FHRR_seq(*args): ###emperical, sequential normalization\n",
        "  ret = np.zeros(len(args[0][0]), dtype=complex)\n",
        "\n",
        "  for v in args[0]:\n",
        "    ret = np.add(ret, v)\n",
        "    l2 = norm(ret)\n",
        "\n",
        "    if l2 == 0:\n",
        "      raise ValueError(\"For some reason, bundled vec is the 0 vector\")\n",
        "\n",
        "  return (ret / l2)\n",
        "\n",
        "def bundle_FHRR(*args): ###empirical normalization\n",
        "  ret = np.zeros(len(args[0][0]), dtype=complex)\n",
        "  for v in args[0]:\n",
        "    ret = np.add(ret, v)\n",
        "\n",
        "  l2 = norm(ret)\n",
        "  if l2 == 0:\n",
        "     raise ValueError(\"For some reason, bundled vec is the 0 vector\")\n",
        "\n",
        "  return (ret / l2)\n",
        "\n",
        "def sim_FHRR(vec1, vec2):\n",
        "  return np.real((dot(vec1, np.conjugate(vec2)))) / len(vec1)"
      ],
      "metadata": {
        "id": "7Dbh7iDH4Dm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capacity Analysis experiment! This takes FOREVER (Upto 10 hours). Results here are just what you get from one time. Not a whole lot of value in repeating it 10 times as you can fit straight lines. I tried being as optimal as I could with array operations. I also don't know much about Python multiprocessing yet so maybe that's why too. But not about to implement the vector stuff in C so this is what we get!!\n",
        "\n",
        "If you want to wait for it to run then you'll see that yes, you get the same results qualitatively as the paper. If you run it locally with more cores it's way faster.\n",
        "\n",
        "I could have also optimized it by guessing a lower bound on the minimum number of dimensions but that struck me as scientifically dishonest so instead we just get this horribly slow code.\n",
        "\n",
        "The assigment gets the experiment details wrong. Here I implemented the experiment from the paper."
      ],
      "metadata": {
        "id": "KpjyM4PVQ8dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def capacity_analysis(generate, bundle, similarity, complex_elements, name):\n",
        "  output = np.zeros(50)\n",
        "  for i in range(5, len(output)): ### number of vectors we are bundling\n",
        "\n",
        "    for j in range(5, 10000): ### j is the dimension of the vector space. We will usually break out of this loop much earlier than j = 10,000.\n",
        "\n",
        "      strike = 0\n",
        "\n",
        "      if complex_elements:\n",
        "        item_memory = np.ndarray((1000, j), dtype=complex)\n",
        "\n",
        "      else:\n",
        "        item_memory = np.ndarray((1000, j))\n",
        "\n",
        "      for k in range(1000):\n",
        "        item_memory[k] = generate(j) ### generate random vector of this architecture of dim j, populating item memory\n",
        "\n",
        "\n",
        "      for _ in range(100):\n",
        "        random_indices = np.random.randint(0, 1000, i)\n",
        "        elementary_vectors = np.array(item_memory[random_indices]) ### vectors we are bundling\n",
        "        bound_vec = bundle(elementary_vectors) ### bundled vector\n",
        "\n",
        "        similarities = []\n",
        "        for idx in range(1000):\n",
        "          similarities.append(similarity(bound_vec, item_memory[idx]))\n",
        "\n",
        "        sorted_indices = np.argsort(similarities)[::-1] ### get the indeces sorted in order of similarity to bundled vector\n",
        "\n",
        "        query_response = item_memory[sorted_indices][:i] ### get the i most similar vectors\n",
        "\n",
        "        m = (query_response[:, None] == elementary_vectors).all(-1).any(1) ### this is a mask which when applied to query_response,\n",
        "                                                                          ### gives the intersection of query response and elem vecs. next code cell has an example\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if (len(query_response[m]) < len(elementary_vectors)):\n",
        "          strike += 1\n",
        "        if (strike >= 2): ### 2 failed retrievals out of 100 --> less than 99% accuracy\n",
        "          break\n",
        "\n",
        "\n",
        "\n",
        "      if (strike <= 1):\n",
        "        print(name + \" with \" + str(i) + \" bundled vectors. Dimension for 99% accuracy = \" + str(j))\n",
        "        output[i] = j\n",
        "        break\n",
        "\n",
        "\n",
        "  return output\n",
        "\n",
        "VSA_Settings = [(generate_MAP_vector, MAP_bundle, MAP_similarity, False, \"MAP\"),\n",
        "                 (generate_HRR_vector, bundle_HRR, similarity_HRR,  False, \"HRR\"),\n",
        "                (generate_FHRR_vector, bundle_FHRR, sim_FHRR, True, \"FHRR\"),\n",
        "                (generate_FHRR_vector, bundle_FHRR_seq, sim_FHRR, True, \"FHRR seq norm\")\n",
        "                 ]\n",
        "lowest_dimensions = np.zeros((4,50))\n",
        "\n",
        "\n",
        "\n",
        "pool = Pool()\n",
        "\n",
        "lowest_dimensions = np.add(lowest_dimensions, pool.starmap(capacity_analysis, VSA_Settings))\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "###lowest_dimensions[0] = np.add(lowest_dimensions[0], capacity_analysis(generate_MAP_vector, MAP_bundle, MAP_similarity, False, \"MAP\"))\n",
        "###lowest_dimensions[1] = np.add(lowest_dimensions[1], capacity_analysis(generate_HRR_vector, bundle_HRR, sim_HRR, False, \"HRR\"))\n",
        "###lowest_dimensions[2] = np.add(lowest_dimensions[2], capacity_analysis(generate_FHRR_vector, bundle_FHRR, sim_FHRR, True, \"FHRR\"))\n",
        "###lowest_dimensions[3] = np.add(lowest_dimensions[3], capacity_analysis(generate_FHRR_vector, bundle_FHRR_seq, sim_FHRR, True, \"FHRR seq norm\"))\n",
        "\n",
        "plt.plot(lowest_dimensions[0], label = \"MAP\")\n",
        "plt.plot(lowest_dimensions[1], label = \"HRR\")\n",
        "plt.plot(lowest_dimensions[2], label = \"FHRR\")\n",
        "plt.plot(lowest_dimensions[3], label = \"FHRR_Sequential_Normalization\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fnEfSDDOL6CM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5164908-ca3f-4073-86ed-945729987654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HRR with 5 bundled vectors. Dimension for 99% accuracy = 162\n",
            "HRR with 6 bundled vectors. Dimension for 99% accuracy = 182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process ForkPoolWorker-2:\n",
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-10-7b8e62b801d2>\", line 26, in capacity_analysis\n",
            "    similarities.append(similarity(bound_vec, item_memory[idx]))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "  File \"<ipython-input-10-7b8e62b801d2>\", line 26, in capacity_analysis\n",
            "    similarities.append(similarity(bound_vec, item_memory[idx]))\n",
            "  File \"<__array_function__ internals>\", line 180, in norm\n",
            "  File \"<ipython-input-8-59152d431d9f>\", line 27, in similarity_HRR\n",
            "    return dot(vector1, vector2)/(norm(vector1)*norm(vector2))\n",
            "  File \"<ipython-input-6-6f1dbf6fe361>\", line 21, in MAP_similarity\n",
            "    return dot(vector1, vector2)/(norm(vector1)*norm(vector2))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7b8e62b801d2>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mlowest_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowest_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapacity_analysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVSA_Settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         '''\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  File \"<__array_function__ internals>\", line 180, in norm\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\", line 2512, in norm\n",
            "    x = x.ravel(order='K')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\", line 2513, in norm\n",
            "    if isComplexType(x.dtype.type):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\", line 116, in isComplexType\n",
            "    def isComplexType(t):\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "A = np.array([[1,4],[2,5],[3,6]])\n",
        "B = np.array([[1,4],[3,6],[7,8]])\n",
        "\n",
        "m = (A[:, None] == B).all(-1).any(1)\n",
        "\n",
        "A[m]"
      ],
      "metadata": {
        "id": "1qyfCjVTUOJi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}